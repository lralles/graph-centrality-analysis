{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Graphs Impact Analysis\n",
    "\n",
    "This notebook analyzes the impact of removing the highest-degree node from different types of random graphs on various centrality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: workaround to avoid ipynb import errors\n",
    "import os\n",
    "import sys\n",
    "\n",
    "candidate_roots = [\n",
    "    os.getcwd(),\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    os.path.dirname(os.path.dirname(os.getcwd())),\n",
    "]\n",
    "for root in candidate_roots:\n",
    "    src_dir = os.path.join(root, \"src\")\n",
    "    if os.path.isdir(src_dir) and src_dir not in sys.path:\n",
    "        sys.path.append(src_dir)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# define centrality metrics for the analysis\n",
    "centrality_functions = {\n",
    "    \"degree\": nx.degree_centrality,\n",
    "    \"betweenness\": nx.betweenness_centrality,\n",
    "    \"closeness\": nx.closeness_centrality,\n",
    "    \"eigenvector\": lambda G: nx.eigenvector_centrality(G, max_iter=5000),\n",
    "    # Use numpy variant to avoid error on larger graphs,TODO: results are weird, need to check later\n",
    "    \"katz\": lambda G: nx.katz_centrality_numpy(G, alpha=0.01, beta=1.0),\n",
    "}\n",
    "\n",
    "# define graph sizes\n",
    "sizes = [10, 100, 1000]\n",
    "\n",
    "# define graph types\n",
    "graph_types = [\n",
    "    \"erdos_renyi\", \n",
    "    \"barabasi_albert\", \n",
    "    \"watts_strogatz\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_build_utlis import make_graph, highest_degree_node\n",
    "from node_removal_graph_analyser import get_node_removal_impact\n",
    "\n",
    "# compute the differences in centrality\n",
    "results = []\n",
    "for size in sizes:\n",
    "    for gtype in graph_types:\n",
    "        G = make_graph(gtype, size)\n",
    "        node = highest_degree_node(G)\n",
    "\n",
    "        for metric_name, metric_fn in centrality_functions.items():\n",
    "            # TODO: add try catch to avoid plotting calculated errors, likely happening on katz\n",
    "            elapsed, impact = get_node_removal_impact(G, node, metric_fn)\n",
    "            results.append({\n",
    "                \"size\": size,\n",
    "                \"graph_type\": gtype,\n",
    "                \"metric\": metric_name,\n",
    "                \"impact\": impact,\n",
    "                \"graph\": G\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "# TODO: save plots to results folders\n",
    "\n",
    "pos_cache = {}\n",
    "\n",
    "# plot the resulting graphs\n",
    "for r in results:\n",
    "    size = r[\"size\"]\n",
    "    gtype = r[\"graph_type\"]\n",
    "    metric = r[\"metric\"]\n",
    "    impact = r[\"impact\"]\n",
    "    G = r[\"graph\"]\n",
    "    \n",
    "    removed_node = highest_degree_node(G)\n",
    "\n",
    "    # layout cache per (graph_type, size)\n",
    "    # This ensures graphs of same size and type are shown with nodes in the same positions\n",
    "    # The seed is just a random number, 42 is used a pop-culture reference\n",
    "    # The K parameter here is used to optimize node distances, for larger graphs, it should be smaller\n",
    "    # the pos value will be used in the plot\n",
    "    key = (gtype, size)\n",
    "    if key not in pos_cache:\n",
    "        if size >= 500:\n",
    "            pos_cache[key] = nx.spring_layout(G, seed=42, k=1 / np.sqrt(size))\n",
    "        else:\n",
    "            pos_cache[key] = nx.spring_layout(G, seed=42)\n",
    "    pos = pos_cache[key]\n",
    "\n",
    "    # normalize impacts for color mapping\n",
    "    # outputs norm, norm is a normalization function created based on the max absolute value\n",
    "    max_abs = max((abs(v) for v in impact.values()), default=0.0)\n",
    "    if max_abs == 0:\n",
    "        norm = colors.TwoSlopeNorm(vmin=-1.0, vcenter=0.0, vmax=1.0)\n",
    "    else:\n",
    "        norm = colors.TwoSlopeNorm(vmin=-max_abs, vcenter=0.0, vmax=max_abs)\n",
    "\n",
    "    # build node colors\n",
    "    # node_colors stores the colors of each nodes, based on the index\n",
    "    # cmap creates the blue white red color scheme\n",
    "    # the removed node gets the yellow color\n",
    "    # the normalized value by norm is passed to the cmap(bwr) that than returns the color\n",
    "    cmap = plt.get_cmap(\"bwr\")\n",
    "    node_colors = []\n",
    "    for n in G.nodes():\n",
    "        if n == removed_node:\n",
    "            node_colors.append(\"yellow\")\n",
    "        else:\n",
    "            node_colors.append(cmap(norm(impact.get(n, 0.0))))\n",
    "\n",
    "    # visual parameters by size\n",
    "    # defined experimentally, based on the used graphs sizes\n",
    "    if size >= 500:\n",
    "        node_size = 10\n",
    "        edge_width = 0.2\n",
    "    elif size >= 100:\n",
    "        node_size = 25\n",
    "        edge_width = 0.3\n",
    "    else:\n",
    "        node_size = 200\n",
    "        edge_width = 0.6\n",
    "\n",
    "    # create figure\n",
    "    # ax will be used for the colorbar scale\n",
    "    # 0.8 is the border thickness, used to diffrrentiate from the white background\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_size,\n",
    "        edge_color=\"lightgrey\",\n",
    "        width=edge_width,\n",
    "        ax=ax,\n",
    "        with_labels=False,\n",
    "        linewidths=0.8,\n",
    "        edgecolors=\"black\"\n",
    "    )\n",
    "    # set label\n",
    "    ax.set_title(f\"{gtype}, n={size}, metric={metric}\")\n",
    "\n",
    "    # colorbar for impact scale\n",
    "    # creates the color scale on the side of the images, based on the color map and normalized values\n",
    "    # 0.046 defines the widht of the scale bar in 0,04 the padding to the rest of the plot\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.04, pad=0.05)\n",
    "    cbar.set_label(\"Î” centrality\")\n",
    "\n",
    "    # save image to results\n",
    "    safe_filename = f\"{gtype}-{size}-{metric}\"\n",
    "    filepath = f\"../../results/random-graphs-impact/images/{safe_filename}.png\"\n",
    "    \n",
    "    # Save the plot instead of showing it\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create degrees distributions of graphs and impact on centrality metrics, compare to degree distrubuitions\n",
    "# what values are expected for certain metrics, \n",
    "# for example, closeness normally does not create positive impact, degree shouldn't as well, but does so beacause of normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
